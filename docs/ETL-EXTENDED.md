# El Viaje de los Datos en TSI: De JSON a Insight

**Un storytelling t√©cnico del proceso ETL en Telescope Scheduling Intelligence**

---

## Pr√≥logo: El Problema que Resolvemos

Imagina que eres un operador de un telescopio astron√≥mico. Acabas de recibir un fichero JSON con miles de bloques de observaci√≥n: cada uno con sus coordenadas celestes, ventanas temporales, restricciones de altitud y azimut, prioridades cient√≠ficas. Este fichero representa semanas de trabajo cient√≠fico, cientos de horas de observaci√≥n, y millones de d√≥lares en inversi√≥n.

Necesitas responder preguntas urgentes:
- ¬øQu√© porcentaje de los bloques es realmente observable?
- ¬øD√≥nde est√°n concentrados los targets en el cielo?
- ¬øHay conflictos temporales entre bloques de alta prioridad?
- ¬øC√≥mo se compara este schedule con el anterior?

**El problema**: Hacer an√°lisis complejos sobre datos astron√≥micos requiere JOINs de 6-7 tablas, agregaciones costosas, parsing de JSON en tiempo real. Una consulta puede tardar segundos o minutos. La experiencia de usuario se degrada. La productividad cient√≠fica sufre.

**La soluci√≥n**: TSI implementa un proceso ETL sofisticado que transforma datos normalizados en un formato anal√≠tico optimizado, reduciendo consultas de segundos a milisegundos. Este es el viaje de esos datos.

---

## Cap√≠tulo 1: El Punto de Entrada ‚Äî Upload y Primera Validaci√≥n

### 1.1 El Schedule Llega a Puerto

Todo comienza cuando un operador sube un fichero `schedule.json` a trav√©s de la interfaz de TSI. Este fichero contiene la representaci√≥n cruda del plan de observaci√≥n:

```json
{
  "schedulingBlocks": [
    {
      "schedulingBlockId": "NGC1234_001",
      "target": {
        "name": "NGC 1234",
        "ICRS": {"ra": 45.67, "dec": -23.45}
      },
      "priority": 0.85,
      "requestedDuration": 3600,
      "minObservation": 1800,
      "constraints": {...},
      "visibilityPeriods": [...]
    },
    ...
  ],
  "darkPeriods": [...]
}
```

El primer guardi√°n en este viaje es el **backend Rust**, espec√≠ficamente las funciones de parsing que viven en `backend/src/db/repositories/`. Rust no perdona: si el JSON est√° malformado, si falta un campo obligatorio, si un valor num√©rico no puede parsearse, el sistema rechaza el upload antes de que toque la base de datos.

### 1.2 El Sello de Identidad: SHA-256 Checksum

Antes de procesar el schedule, TSI calcula un **checksum SHA-256** del contenido completo del JSON. Este hash act√∫a como una huella digital √∫nica del schedule.

**¬øPor qu√© es cr√≠tico?**
- **Idempotencia**: Si subes el mismo schedule dos veces (accidentalmente o a prop√≥sito), el sistema lo detecta inmediatamente por el checksum.
- **Auditor√≠a**: Podemos rastrear exactamente qu√© versi√≥n del schedule se proces√≥.
- **Integridad**: Cualquier cambio m√≠nimo en el JSON produce un checksum diferente.

El checksum se almacena en `dbo.schedules` con un constraint √∫nico (`UNIQUE (checksum)`), garantizando que duplicados sean rechazados a nivel de base de datos.

```sql
CREATE TABLE dbo.schedules (
    schedule_id      BIGINT IDENTITY(1,1) PRIMARY KEY,
    schedule_name    NVARCHAR(256) NOT NULL,
    upload_timestamp DATETIMEOFFSET(3) NOT NULL DEFAULT SYSUTCDATETIME(),
    checksum         NVARCHAR(64) NOT NULL,
    dark_periods_json NVARCHAR(MAX) NULL,
    CONSTRAINT UQ_schedules_checksum UNIQUE (checksum)
);
```

Con el checksum validado y un nuevo `schedule_id` asignado, el schedule est√° listo para su descomposici√≥n.

---

## Cap√≠tulo 2: La Normalizaci√≥n ‚Äî Desestructurando para Integridad

### 2.1 Por Qu√© Normalizar en la Era de NoSQL

En 2025, muchos sistemas van directamente a estructuras de documentos (MongoDB, CosmosDB, etc.). TSI toma un camino diferente: **descompone el JSON en una estructura relacional 3NF (Tercera Forma Normal)**.

**Motivaci√≥n**:
1. **Integridad Referencial**: Las foreign keys garantizan que no puedes tener un scheduling block apuntando a un target inexistente.
2. **Deduplicaci√≥n**: M√∫ltiples bloques pueden apuntar al mismo target (M87, por ejemplo). Con normalizaci√≥n, almacenamos las coordenadas de M87 una sola vez.
3. **Consistencia Transaccional**: Si algo falla a mitad del proceso, un ROLLBACK deshace todo. No quedamos en estado inconsistente.
4. **Auditabilidad**: Cada entidad tiene su propia tabla, su propio ID, su propio historial.

### 2.2 El Proceso de Descomposici√≥n

El backend Rust analiza el JSON y construye un **grafo de dependencias** en memoria. Imagina que cada scheduling block es un nodo que apunta a:
- Un **target** (definido por RA, Dec, proper motion)
- Unas **altitude constraints** (min/max altitud)
- Unas **azimuth constraints** (min/max azimut)
- Unas **constraints** (combinaci√≥n de tiempo + altitud + azimut)
- Una lista de **visibility periods** (ventanas donde el target es observable)

El sistema procede en **orden topol√≥gico** para respetar las foreign keys:

#### 2.2.1 Paso 1: Inserci√≥n del Schedule Ra√≠z

```sql
INSERT INTO dbo.schedules (schedule_name, checksum, dark_periods_json)
VALUES ('Schedule_2025-12-01', '5a7b9c...', '[{"start": 60340.5, "stop": 60341.5}, ...]');
-- Retorna: schedule_id = 123
```

#### 2.2.2 Paso 2: Targets ‚Äî Deduplicaci√≥n por Coordenadas

Cada target se define por `(ra_deg, dec_deg, ra_pm_masyr, dec_pm_masyr, equinox)`. TSI usa un **UNIQUE constraint** en estas columnas:

```sql
CREATE TABLE dbo.targets (
    target_id       BIGINT IDENTITY(1,1) PRIMARY KEY,
    name            NVARCHAR(MAX) NOT NULL,
    ra_deg          FLOAT NOT NULL,
    dec_deg         FLOAT NOT NULL,
    ra_pm_masyr     FLOAT NOT NULL DEFAULT 0,
    dec_pm_masyr    FLOAT NOT NULL DEFAULT 0,
    equinox         FLOAT NOT NULL DEFAULT 2000.0,
    CONSTRAINT targets_unique_natural_flat UNIQUE (ra_deg, dec_deg, ra_pm_masyr, dec_pm_masyr, equinox),
    CONSTRAINT valid_ra_dec_flat CHECK (ra_deg >= 0 AND ra_deg < 360 AND dec_deg >= -90 AND dec_deg <= 90)
);
```

**Estrategia de inserci√≥n**:
1. Intenta `INSERT`.
2. Si falla por violaci√≥n de UNIQUE, realiza un `SELECT` para obtener el `target_id` existente.
3. Reutiliza ese `target_id` para los scheduling blocks que referencian ese target.

**Resultado**: Si 500 bloques apuntan a M87, insertamos M87 una sola vez y creamos 500 referencias a ese mismo `target_id`.

#### 2.2.3 Paso 3: Altitude y Azimuth Constraints ‚Äî Deduplicaci√≥n por Rangos

Similar l√≥gica:

```sql
CREATE TABLE dbo.altitude_constraints (
    altitude_constraints_id BIGINT IDENTITY(1,1) PRIMARY KEY,
    min_alt_deg             FLOAT NOT NULL DEFAULT 0,
    max_alt_deg             FLOAT NOT NULL DEFAULT 90,
    CONSTRAINT altitude_constraints_range_chk_flat CHECK (min_alt_deg <= max_alt_deg),
    CONSTRAINT altitude_constraints_unique_flat UNIQUE (min_alt_deg, max_alt_deg)
);
```

Si 100 bloques comparten las mismas restricciones de altitud (20¬∞-70¬∞), insertamos una fila y reutilizamos el ID.

#### 2.2.4 Paso 4: Constraints ‚Äî Combinaci√≥n Reusable

Una `constraint` combina:
- Ventana temporal (`start_time_mjd`, `stop_time_mjd`)
- Restricci√≥n de altitud (FK a `altitude_constraints`)
- Restricci√≥n de azimut (FK a `azimuth_constraints`)

```sql
CREATE TABLE dbo.constraints (
    constraints_id          BIGINT IDENTITY(1,1) PRIMARY KEY,
    start_time_mjd          FLOAT NULL,
    stop_time_mjd           FLOAT NULL,
    altitude_constraints_id BIGINT NULL REFERENCES dbo.altitude_constraints(altitude_constraints_id),
    azimuth_constraints_id  BIGINT NULL REFERENCES dbo.azimuth_constraints(azimuth_constraints_id),
    CONSTRAINT constraints_unique_combo_flat UNIQUE (start_time_mjd, stop_time_mjd, altitude_constraints_id, azimuth_constraints_id)
);
```

**Por qu√© esto importa**: Si 50 bloques tienen exactamente las mismas restricciones espacio-temporales, no duplicamos datos. Ahorramos espacio, mejoramos cache locality, simplificamos actualizaciones.

#### 2.2.5 Paso 5: Scheduling Blocks ‚Äî El Core del Schedule

Cada scheduling block es una fila:

```sql
CREATE TABLE dbo.scheduling_blocks (
    scheduling_block_id    BIGINT IDENTITY(1,1) PRIMARY KEY,
    original_block_id      NVARCHAR(256) NULL,  -- schedulingBlockId del JSON
    target_id              BIGINT NOT NULL REFERENCES dbo.targets(target_id),
    constraints_id         BIGINT NULL REFERENCES dbo.constraints(constraints_id),
    priority               FLOAT NOT NULL,
    min_observation_sec    INT NOT NULL,
    requested_duration_sec INT NOT NULL,
    visibility_periods_json NVARCHAR(MAX) NULL,  -- ¬°Almacenado como JSON!
    CONSTRAINT valid_min_obs_req_dur_flat CHECK (min_observation_sec <= requested_duration_sec)
);
```

**Decisi√≥n de dise√±o clave**: Los **visibility periods** se almacenan como **JSON** dentro de esta tabla. ¬øPor qu√© no normalizar en una tabla separada?

**Razones**:
1. **Cardinalidad Alta**: Un bloque puede tener 100+ periodos de visibilidad. Normalizar crear√≠a millones de filas en una tabla separada.
2. **Acceso Secuencial**: Cuando procesamos un bloque, siempre necesitamos TODOS sus periodos de visibilidad. No hay consultas que pidan "periodos de visibilidad en el rango X independientemente del bloque".
3. **Performance de Parsing**: SQL Server tiene `OPENJSON()` optimizado para parsear JSON columnar in-situ.

**Tradeoff**: Sacrificamos algo de normalizaci√≥n a cambio de simplicidad y rendimiento.

#### 2.2.6 Paso 6: Tabla de Uni√≥n ‚Äî Schedule ‚Üî Scheduling Blocks

Esta es una relaci√≥n **many-to-many**. Un schedule contiene muchos bloques, y (en teor√≠a) un bloque podr√≠a aparecer en m√∫ltiples schedules (aunque en pr√°ctica TSI crea bloques √∫nicos por schedule).

```sql
CREATE TABLE dbo.schedule_scheduling_blocks (
    schedule_id          BIGINT NOT NULL,
    scheduling_block_id  BIGINT NOT NULL,
    start_time_mjd       FLOAT NULL,      -- Si el bloque fue scheduled
    stop_time_mjd        FLOAT NULL,
    duration_sec         AS ((stop_time_mjd - start_time_mjd) * 86400.0) PERSISTED,
    CONSTRAINT PK_schedule_scheduling_blocks_flat PRIMARY KEY (schedule_id, scheduling_block_id),
    CONSTRAINT FK_ssb_schedules_flat FOREIGN KEY (schedule_id) REFERENCES dbo.schedules(schedule_id) ON DELETE CASCADE,
    CONSTRAINT FK_ssb_scheduling_blocks_flat FOREIGN KEY (scheduling_block_id) REFERENCES dbo.scheduling_blocks(scheduling_block_id) ON DELETE CASCADE
);
```

**Nota**: `duration_sec` es una **computed column persistente**. SQL Server la calcula autom√°ticamente y la almacena f√≠sicamente. Esto acelera queries que filtran o ordenan por duraci√≥n.

#### 2.2.7 Paso 7: Dark Periods ‚Äî Periodos Observables

Los dark periods marcan ventanas donde el telescopio puede observar (sin luna ni sol):

```sql
CREATE TABLE dbo.schedule_dark_periods (
    schedule_id     BIGINT NOT NULL REFERENCES dbo.schedules(schedule_id) ON DELETE CASCADE,
    start_time_mjd  FLOAT NOT NULL,
    stop_time_mjd   FLOAT NOT NULL,
    duration_sec    AS ((stop_time_mjd - start_time_mjd) * 86400.0) PERSISTED,
    CONSTRAINT schedule_dark_periods_pk_flat PRIMARY KEY (schedule_id, start_time_mjd, stop_time_mjd)
);
```

### 2.3 Justificaci√≥n de MJD como FLOAT

**Modified Julian Date (MJD)** es el formato temporal est√°ndar en astronom√≠a. TSI usa `FLOAT` en lugar de `DATETIME`:

**Ventajas**:
1. **Precisi√≥n**: FLOAT puede representar tiempos con precisi√≥n de microsegundos en el rango astron√≥mico relevante.
2. **Aritm√©tica Simple**: `stop - start` da duraci√≥n en d√≠as directamente. Multiplicar por 86400 da segundos.
3. **Est√°ndar de Dominio**: Los astr√≥nomos piensan en MJD, no en ISO-8601.

**Tradeoff**: Pierde la validaci√≥n sem√°ntica de `DATETIME`, pero se gana en performance y alineaci√≥n con el dominio.

### 2.4 Estado al Final de la Normalizaci√≥n

Al completar este cap√≠tulo, tenemos:
- ‚úÖ 1 fila en `schedules`
- ‚úÖ ~500 filas en `targets` (deduplicadas de ~5000 bloques)
- ‚úÖ ~50 filas en `altitude_constraints`
- ‚úÖ ~50 filas en `azimuth_constraints`
- ‚úÖ ~200 filas en `constraints`
- ‚úÖ 5000 filas en `scheduling_blocks`
- ‚úÖ 5000 filas en `schedule_scheduling_blocks`
- ‚úÖ ~100 filas en `schedule_dark_periods`

Los datos est√°n **√≠ntegros, consistentes, normalizados**. Pero hacer un an√°lisis r√°pido sobre estos datos requiere JOINs complejos. Aqu√≠ es donde el ETL entra en acci√≥n.

---

## Cap√≠tulo 3: La Gran Transici√≥n ‚Äî Del Mundo Normalizado al Mundo Anal√≠tico

### 3.1 El Problema de Rendimiento

Imagina que un usuario abre la p√°gina de "Trends" en la GUI. La consulta para obtener los datos necesita:

```sql
SELECT 
    sb.priority,
    sb.requested_duration_sec,
    t.ra_deg, t.dec_deg,
    ac.min_alt_deg, ac.max_alt_deg,
    ssb.start_time_mjd, ssb.stop_time_mjd,
    -- Y necesitamos parsear visibility_periods_json...
FROM dbo.schedule_scheduling_blocks ssb
JOIN dbo.scheduling_blocks sb ON ssb.scheduling_block_id = sb.scheduling_block_id
JOIN dbo.targets t ON sb.target_id = t.target_id
LEFT JOIN dbo.constraints c ON sb.constraints_id = c.constraints_id
LEFT JOIN dbo.altitude_constraints ac ON c.altitude_constraints_id = ac.altitude_constraints_id
LEFT JOIN dbo.azimuth_constraints azc ON c.azimuth_constraints_id = azc.azimuth_constraints_id
CROSS APPLY (
    SELECT SUM((CAST(JSON_VALUE(period.value, '$.stop') AS FLOAT) - 
                CAST(JSON_VALUE(period.value, '$.start') AS FLOAT)) * 24.0) AS total_hours
    FROM OPENJSON(sb.visibility_periods_json) AS period
) AS vis
WHERE ssb.schedule_id = 123;
```

**Problemas**:
1. **6-7 JOINs**: Cada uno requiere b√∫squeda de √≠ndice, merging, matching.
2. **Parsing JSON en Runtime**: `OPENJSON()` debe parsear miles de arrays JSON en cada query.
3. **C√°lculos Repetidos**: Cada consulta recalcula `total_visibility_hours`, `priority_bucket`, `elevation_range`, etc.
4. **Latencia Acumulativa**: 100-500ms por query. Inaceptable para una GUI interactiva.

### 3.2 La Filosof√≠a de la Desnormalizaci√≥n Anal√≠tica

TSI adopta una arquitectura **dual-schema**:

- **`dbo.*` (Normalized)**: Source of truth. Integridad, ACID, auditabilidad.
- **`analytics.*` (Denormalized)**: Read-optimized. Velocidad, precomputaci√≥n, zero JOINs.

**Analog√≠a**: Piensa en `dbo.*` como tu almac√©n de datos maestro, y `analytics.*` como tu tienda de conveniencia. Cuando necesitas algo r√°pido, vas a la tienda. Cuando necesitas actualizar inventario, vas al almac√©n.

### 3.3 La Llamada al Proceso ETL

Inmediatamente despu√©s de insertar todos los datos en el esquema normalizado, el backend Rust invoca el stored procedure:

```sql
EXEC analytics.sp_populate_schedule_analytics @schedule_id = 123;
```

Este stored procedure es el **motor del ETL interno**. Es donde la magia ocurre.

---

## Cap√≠tulo 4: El Motor ETL ‚Äî Transformaci√≥n en `sp_populate_schedule_analytics`

### 4.1 Fase 0: Limpieza Idempotente

El primer paso es **borrar** cualquier dato anal√≠tico previo de este schedule:

```sql
DELETE FROM analytics.schedule_blocks_analytics 
WHERE schedule_id = @schedule_id;
```

**¬øPor qu√©?**
- **Idempotencia**: Si re-ejecutas el proceso ETL (porque hubo un error, o porque el schedule fue modificado), no creas duplicados.
- **Limpieza Garantizada**: No hay datos obsoletos o inconsistentes.

### 4.2 Fase 1: C√°lculo de Priority Buckets

TSI agrupa prioridades en **4 buckets** (Low, Medium-Low, Medium-High, High) basados en **cuartiles**:

```sql
DECLARE @priority_min FLOAT, @priority_max FLOAT, @priority_range FLOAT;

SELECT 
    @priority_min = MIN(sb.priority),
    @priority_max = MAX(sb.priority)
FROM dbo.schedule_scheduling_blocks ssb
JOIN dbo.scheduling_blocks sb ON ssb.scheduling_block_id = sb.scheduling_block_id
WHERE ssb.schedule_id = @schedule_id;

SET @priority_range = NULLIF(@priority_max - @priority_min, 0);
```

**L√≥gica de bucketing**:
- Si `priority >= min + 0.75 * range` ‚Üí Bucket 4 (High)
- Si `priority >= min + 0.50 * range` ‚Üí Bucket 3 (Medium-High)
- Si `priority >= min + 0.25 * range` ‚Üí Bucket 2 (Medium-Low)
- Else ‚Üí Bucket 1 (Low)

**¬øPor qu√© cuartiles din√°micos?**
- Diferentes schedules tienen diferentes rangos de prioridad. Un schedule puede ir de 0.1 a 0.9, otro de 50 a 100.
- Los cuartiles **normalizan** la distribuci√≥n para cada schedule, haciendo comparaciones consistentes.

### 4.3 Fase 2: El Gran JOIN ‚Äî Flattening de Entidades

Ahora viene el coraz√≥n del ETL: un **SELECT masivo** que aplana todas las entidades relacionadas:

```sql
INSERT INTO analytics.schedule_blocks_analytics (
    schedule_id,
    scheduling_block_id,
    original_block_id,
    target_ra_deg,
    target_dec_deg,
    priority,
    priority_bucket,
    requested_duration_sec,
    min_observation_sec,
    min_altitude_deg,
    max_altitude_deg,
    min_azimuth_deg,
    max_azimuth_deg,
    constraint_start_mjd,
    constraint_stop_mjd,
    is_scheduled,
    scheduled_start_mjd,
    scheduled_stop_mjd,
    total_visibility_hours,
    visibility_period_count
)
SELECT 
    ssb.schedule_id,
    sb.scheduling_block_id,
    sb.original_block_id,
    t.ra_deg,                    -- Denormalized from targets
    t.dec_deg,                   -- Denormalized from targets
    sb.priority,
    -- Priority bucket: computed inline
    CASE 
        WHEN @priority_range IS NULL THEN 2
        WHEN sb.priority >= @priority_min + 0.75 * @priority_range THEN 4
        WHEN sb.priority >= @priority_min + 0.50 * @priority_range THEN 3
        WHEN sb.priority >= @priority_min + 0.25 * @priority_range THEN 2
        ELSE 1
    END,
    sb.requested_duration_sec,
    sb.min_observation_sec,
    ac.min_alt_deg,              -- Denormalized from altitude_constraints
    ac.max_alt_deg,
    azc.min_az_deg,              -- Denormalized from azimuth_constraints
    azc.max_az_deg,
    c.start_time_mjd,            -- Denormalized from constraints
    c.stop_time_mjd,
    CASE WHEN ssb.start_time_mjd IS NOT NULL THEN 1 ELSE 0 END,
    ssb.start_time_mjd,
    ssb.stop_time_mjd,
    COALESCE(vis.total_hours, 0.0),
    COALESCE(vis.period_count, 0)
FROM dbo.schedule_scheduling_blocks ssb
JOIN dbo.scheduling_blocks sb ON ssb.scheduling_block_id = sb.scheduling_block_id
JOIN dbo.targets t ON sb.target_id = t.target_id
LEFT JOIN dbo.constraints c ON sb.constraints_id = c.constraints_id
LEFT JOIN dbo.altitude_constraints ac ON c.altitude_constraints_id = ac.altitude_constraints_id
LEFT JOIN dbo.azimuth_constraints azc ON c.azimuth_constraints_id = azc.azimuth_constraints_id
OUTER APPLY (
    SELECT 
        SUM(
            CAST(JSON_VALUE(period.value, '$.stop') AS FLOAT) - 
            CAST(JSON_VALUE(period.value, '$.start') AS FLOAT)
        ) * 24.0 AS total_hours,
        COUNT(*) AS period_count
    FROM OPENJSON(sb.visibility_periods_json) AS period
    WHERE sb.visibility_periods_json IS NOT NULL
      AND ISJSON(sb.visibility_periods_json) = 1
) AS vis
WHERE ssb.schedule_id = @schedule_id;
```

### 4.4 Fase 3: Parsing de Visibility Periods con OPENJSON

La cl√°usula `OUTER APPLY` es crucial:

```sql
OUTER APPLY (
    SELECT 
        SUM((stop - start)) * 24.0 AS total_hours,
        COUNT(*) AS period_count
    FROM OPENJSON(sb.visibility_periods_json) AS period
) AS vis
```

**¬øQu√© hace esto?**
1. **Parsea el JSON** `[{"start": 60340.5, "stop": 60341.2}, ...]` en filas.
2. **Calcula duraci√≥n** de cada periodo: `(stop - start)` en d√≠as, multiplicado por 24 para horas.
3. **Agrega**: `SUM()` para total de horas visibles, `COUNT()` para n√∫mero de periodos.

**Resultado**: En lugar de almacenar el JSON crudo, guardamos:
- `total_visibility_hours`: Agregaci√≥n precomputada (ej: 12.5 horas).
- `visibility_period_count`: N√∫mero de ventanas discretas (ej: 5 periodos).

**Ventaja**: Consultas posteriores no necesitan parsear JSON. Simplemente acceden a columnas num√©ricas indexadas.

### 4.5 Fase 4: Computed Columns ‚Äî C√°lculos Persistentes

La tabla `analytics.schedule_blocks_analytics` incluye **computed columns**:

```sql
requested_hours AS (CAST(requested_duration_sec AS FLOAT) / 3600.0) PERSISTED,
elevation_range_deg AS (COALESCE(max_altitude_deg, 90.0) - COALESCE(min_altitude_deg, 0.0)) PERSISTED,
scheduled_duration_sec AS (
    CASE WHEN scheduled_start_mjd IS NOT NULL AND scheduled_stop_mjd IS NOT NULL 
    THEN (scheduled_stop_mjd - scheduled_start_mjd) * 86400.0 
    ELSE NULL END
) PERSISTED,
is_impossible AS (CASE WHEN total_visibility_hours = 0 THEN 1 ELSE 0 END) PERSISTED
```

**`PERSISTED`** significa que SQL Server calcula estos valores **una vez** durante el INSERT, y los almacena f√≠sicamente. Son tan r√°pidos de leer como cualquier otra columna.

**Ejemplos**:
- `requested_hours`: Convierte segundos a horas (m√°s intuitivo para visualizaci√≥n).
- `elevation_range_deg`: Rango de altitudes permitidas (max - min).
- `is_impossible`: Flag binario para bloques con cero visibilidad (√∫til para filtros).

### 4.6 Fase 5: ¬øPor Qu√© NO Usamos Foreign Keys en Analytics?

F√≠jate que `analytics.schedule_blocks_analytics` **no tiene FKs** a `dbo.schedules` o `dbo.scheduling_blocks`.

**Razones**:
1. **Performance**: FKs a√±aden overhead en INSERTs (verificaciones de integridad).
2. **Flexibilidad ETL**: Si queremos borrar un schedule de `dbo.*` pero mantener sus analytics para auditor√≠a, podemos hacerlo.
3. **Eventual Consistency**: Analytics es una **vista materializada**. Es consistente eventualmente, no transaccionalmente.

**Tradeoff**: Perdemos garant√≠as de integridad referencial, pero ganamos velocidad de escritura y flexibilidad operacional.

---

## Cap√≠tulo 5: La Tabla Anal√≠tica ‚Äî Wide Table Optimizada

### 5.1 Anatom√≠a de `schedule_blocks_analytics`

La tabla resultante es una **wide table** (22+ columnas) que contiene TODO lo necesario para consultas anal√≠ticas:

```mermaid
classDiagram
    class schedule_blocks_analytics {
        <<Wide Table Pattern>>
        +BIGINT schedule_id = 123
        +BIGINT scheduling_block_id = 4567
        +NVARCHAR original_block_id = "NGC1234_001"
        ---
        +FLOAT target_ra_deg = 45.67
        +FLOAT target_dec_deg = -23.45
        ---
        +FLOAT priority = 0.85
        +INT priority_bucket = 4 (High)
        ---
        +INT requested_duration_sec = 3600
        +FLOAT requested_hours = 1.0 ‚öôÔ∏è
        +INT min_observation_sec = 1800
        ---
        +FLOAT min_altitude_deg = 30.0
        +FLOAT max_altitude_deg = 70.0
        +FLOAT elevation_range_deg = 40.0 ‚öôÔ∏è
        ---
        +BIT is_scheduled = 1
        +FLOAT scheduled_start_mjd = 60340.56789
        +FLOAT scheduled_stop_mjd = 60340.60903
        +FLOAT scheduled_duration_sec = 3553.5 ‚öôÔ∏è
        ---
        +FLOAT total_visibility_hours = 8.5 üìä
        +INT visibility_period_count = 3 üìä
        +BIT is_impossible = 0 üìä
    }
    
    note for schedule_blocks_analytics "22+ columnas desnormalizadas\n‚öôÔ∏è = Columna computada\nüìä = Pre-computed from JSON\nOptimizado para queries anal√≠ticas"
```

### 5.2 Indexaci√≥n Estrat√©gica

TSI crea √≠ndices **espec√≠ficos para patrones de consulta**:

#### √çndice 1: Primary Access ‚Äî Todos los Bloques de un Schedule

```sql
CREATE INDEX IX_analytics_schedule_id 
    ON analytics.schedule_blocks_analytics (schedule_id) 
    INCLUDE (scheduling_block_id, priority, target_ra_deg, target_dec_deg, is_scheduled);
```

**Uso**: Cualquier consulta que empiece con `WHERE schedule_id = 123`.

**Optimizaci√≥n**: INCLUDE a√±ade columnas extra sin aumentar el tama√±o del B-tree. SQL Server puede hacer un **index-only scan** sin tocar la tabla base.

#### √çndice 2: Sky Map ‚Äî Proyecci√≥n Celeste

```sql
CREATE INDEX IX_analytics_sky_map 
    ON analytics.schedule_blocks_analytics (schedule_id, priority_bucket)
    INCLUDE (target_ra_deg, target_dec_deg, scheduled_start_mjd, scheduled_stop_mjd);
```

**Uso**: P√°gina "Sky Map" que muestra distribuci√≥n de targets por RA/Dec.

**Beneficio**: Filtrar por schedule + priority_bucket, obtener coordenadas y estado de scheduling sin tabla scan.

#### √çndice 3: Distributions ‚Äî Histogramas y Estad√≠sticas

```sql
CREATE INDEX IX_analytics_distribution 
    ON analytics.schedule_blocks_analytics (schedule_id, is_impossible)
    INCLUDE (priority, total_visibility_hours, requested_hours, elevation_range_deg, is_scheduled);
```

**Uso**: P√°gina "Distributions" que calcula histogramas de prioridad, visibilidad, etc.

**Beneficio**: Excluir bloques imposibles (`is_impossible = 0`) se vuelve trivial.

#### √çndice 4: Timeline ‚Äî Bloques Scheduled

```sql
CREATE INDEX IX_analytics_scheduled 
    ON analytics.schedule_blocks_analytics (schedule_id, is_scheduled)
    WHERE scheduled_start_mjd IS NOT NULL;
```

**Uso**: P√°gina "Timeline" que muestra bloques en su ventana temporal de ejecuci√≥n.

**Beneficio**: **Filtered index** ‚Äî solo indexa filas donde hay scheduling. Reduce espacio y mejora velocidad.

#### √çndice 5: Impossible Blocks ‚Äî Filtrado de Zero Visibility

```sql
CREATE INDEX IX_analytics_impossible 
    ON analytics.schedule_blocks_analytics (schedule_id, total_visibility_hours)
    WHERE total_visibility_hours = 0;
```

**Uso**: Checkboxes "Exclude impossible blocks" en varias vistas.

**Beneficio**: Identificar bloques con cero visibilidad en O(1).

### 5.3 Ventajas de la Wide Table

**1. Zero JOINs en Consultas Anal√≠ticas**

Compara:

‚ùå **Sin Analytics (Normalized)**:
```sql
-- 6 JOINs, OPENJSON en runtime
SELECT ...
FROM dbo.schedule_scheduling_blocks ssb
JOIN dbo.scheduling_blocks sb ON ...
JOIN dbo.targets t ON ...
LEFT JOIN dbo.constraints c ON ...
LEFT JOIN dbo.altitude_constraints ac ON ...
LEFT JOIN dbo.azimuth_constraints azc ON ...
CROSS APPLY OPENJSON(sb.visibility_periods_json) ...
WHERE ssb.schedule_id = 123;
```

‚úÖ **Con Analytics (Denormalized)**:
```sql
-- Zero JOINs, datos precomputados
SELECT 
    priority, 
    total_visibility_hours, 
    requested_hours,
    is_scheduled
FROM analytics.schedule_blocks_analytics
WHERE schedule_id = 123;
```

**Resultado**: Latencia reducida de ~200ms a ~10ms (20x m√°s r√°pido).

**2. Predicabilidad de Rendimiento**

Todas las consultas anal√≠ticas tienen **complejidad O(n)** donde n = n√∫mero de bloques en el schedule. No hay dependencia de tama√±o de tablas relacionadas o complejidad de JOINs.

**3. Optimizaci√≥n para Column Store**

Aunque TSI actualmente usa row-store, la wide table est√° **lista para migrar a columnstore indexes** si el volumen crece. Columnstore es ideal para:
- Tablas anchas con muchas columnas.
- Consultas que leen subsets de columnas (proyecciones).
- Agregaciones sobre millones de filas.

---

## Cap√≠tulo 6: Validaci√≥n del Schedule ‚Äî Marcando lo Imposible

### 6.1 El Problema de Scheduling Imposible

No todos los bloques en un schedule son realizables:
- **Zero Visibility**: El target nunca est√° sobre el horizonte en el rango temporal dado.
- **Ventana Temporal Insuficiente**: El bloque requiere 2 horas, pero solo hay 30 minutos de visibilidad.
- **Conflictos de Restricciones**: Las constraints de altitud y azimut son imposibles de satisfacer simult√°neamente.

TSI ejecuta **reglas de validaci√≥n** (implementadas en Python/Rust) que consumen `analytics.schedule_blocks_analytics` y detectan estos casos.

### 6.2 Almacenamiento de Resultados de Validaci√≥n

Los resultados se insertan en:

```sql
CREATE TABLE analytics.schedule_validation_results (
    id BIGINT IDENTITY(1,1) PRIMARY KEY,
    schedule_id BIGINT NOT NULL,
    scheduling_block_id BIGINT NOT NULL,
    rule_name NVARCHAR(256) NOT NULL,
    severity NVARCHAR(50) NOT NULL,  -- 'ERROR', 'WARNING', 'INFO'
    message NVARCHAR(MAX) NOT NULL,
    validation_timestamp DATETIME2 NOT NULL DEFAULT GETUTCDATE()
);
```

**Ejemplo de fila**:
```
schedule_id: 123
scheduling_block_id: 4567
rule_name: "ZeroVisibilityRule"
severity: "ERROR"
message: "Block has 0 hours of visibility. Cannot be scheduled."
```

### 6.3 Actualizaci√≥n del Flag `validation_impossible`

Las reglas de validaci√≥n actualizan el campo `validation_impossible` en analytics:

```sql
UPDATE analytics.schedule_blocks_analytics
SET validation_impossible = 1
WHERE schedule_id = 123
  AND scheduling_block_id IN (SELECT scheduling_block_id FROM analytics.schedule_validation_results WHERE severity = 'ERROR');
```

Ahora, la GUI puede filtrar bloques imposibles con:

```sql
WHERE validation_impossible = 0
```

---

## Cap√≠tulo 7: Consulta de Datos desde la GUI ‚Äî El Usuario Final

### 7.1 El Flujo de una Consulta T√≠pica

Un usuario abre la p√°gina **"Distributions"** en la GUI Streamlit. Quiere ver un histograma de prioridades excluyendo bloques imposibles.

**Secuencia**:

1. **Streamlit (Python)** ‚Üí `tsi.services.backend_client.get_distribution_data(schedule_ref=123)`

2. **Python Service Layer** ‚Üí Llama al **Rust backend** via PyO3:
   ```python
   from tsi_rust import py_get_distribution_data
   data = py_get_distribution_data(schedule_id)
   ```

3. **Rust Backend** ‚Üí Crea un **Tokio async runtime** y ejecuta:
   ```rust
   let blocks = fetch_analytics_blocks_for_distributions(pool, schedule_id).await?;
   ```

4. **Consulta SQL** (ejecutada por Rust):
   ```sql
   SELECT 
       priority,
       priority_bucket,
       total_visibility_hours,
       requested_hours,
       is_scheduled
   FROM analytics.schedule_blocks_analytics
   WHERE schedule_id = @p1
   ```

5. **Azure SQL Database** ‚Üí **Index seek** en `IX_analytics_distribution`, retorna ~5000 filas en ~10ms.

6. **Rust** ‚Üí Procesa resultados, construye histogramas, retorna a Python.

7. **Streamlit** ‚Üí Renderiza gr√°fico con Plotly.

### 7.2 Ejemplos Narrativos de Consultas

#### Sky Map ‚Äî Distribuci√≥n Celeste

**Pregunta**: ¬øD√≥nde est√°n concentrados los targets en el cielo?

**Query**:
```sql
SELECT 
    target_ra_deg,
    target_dec_deg,
    priority_bucket,
    is_scheduled
FROM analytics.schedule_blocks_analytics
WHERE schedule_id = 123;
```

**√çndice usado**: `IX_analytics_sky_map`

**Resultado**: Plotly scatter plot en coordenadas RA/Dec con colores por prioridad.

#### Distribuciones de Prioridad

**Pregunta**: ¬øCu√°ntos bloques hay en cada bucket de prioridad?

**Query**:
```sql
SELECT 
    priority_bucket,
    COUNT(*) AS block_count
FROM analytics.schedule_blocks_analytics
WHERE schedule_id = 123
  AND validation_impossible = 0
GROUP BY priority_bucket;
```

**√çndice usado**: `IX_analytics_distribution`

**Resultado**: Bar chart con 4 barras (Low, Med-Low, Med-High, High).

#### Timeline ‚Äî Bloques Scheduled en el Tiempo

**Pregunta**: ¬øCu√°ndo se ejecuta cada bloque scheduled?

**Query**:
```sql
SELECT 
    original_block_id,
    scheduled_start_mjd,
    scheduled_stop_mjd,
    scheduled_duration_sec,
    priority
FROM analytics.schedule_blocks_analytics
WHERE schedule_id = 123
  AND is_scheduled = 1
ORDER BY scheduled_start_mjd;
```

**√çndice usado**: `IX_analytics_scheduled`

**Resultado**: Gantt chart con bloques en eje temporal.

#### Insights ‚Äî Issues de Validaci√≥n

**Pregunta**: ¬øQu√© bloques tienen problemas?

**Query**:
```sql
SELECT 
    v.scheduling_block_id,
    a.original_block_id,
    v.rule_name,
    v.severity,
    v.message
FROM analytics.schedule_validation_results v
JOIN analytics.schedule_blocks_analytics a ON v.scheduling_block_id = a.scheduling_block_id
WHERE v.schedule_id = 123
  AND v.severity = 'ERROR'
ORDER BY v.validation_timestamp DESC;
```

**Resultado**: Tabla con lista de errores y warnings.

### 7.3 Ventajas de Latencia Baja

**User Experience**:
- **Interactividad**: Cambiar filtros ("Exclude impossible", "Only high priority") refresca la vista en <50ms.
- **Responsiveness**: Switching entre p√°ginas (Sky Map ‚Üí Distributions ‚Üí Timeline) es instant√°neo.
- **Escalabilidad**: Un schedule con 10,000 bloques se siente tan r√°pido como uno con 500 bloques.

**Technical Metrics**:
- **p50 latency**: ~10ms
- **p95 latency**: ~30ms
- **p99 latency**: ~50ms

Comparado con:
- **p50 sin analytics**: ~200ms
- **p95 sin analytics**: ~800ms
- **p99 sin analytics**: ~2000ms

---

## Cap√≠tulo 8: Opcionales y Extensiones ‚Äî Evoluci√≥n del Sistema

### 8.1 ¬øQu√© Pasa si el Schedule Base se Modifica?

**Escenario**: Un operador actualiza un scheduling block en `dbo.scheduling_blocks` (cambia `priority` o `requested_duration_sec`).

**Problema**: Los datos en `analytics.*` quedan **obsoletos**.

**Soluciones**:

#### Opci√≥n A: Refresh Manual
```sql
EXEC analytics.sp_populate_schedule_analytics @schedule_id = 123;
```

El operador re-ejecuta el ETL manualmente. Simple, pero propenso a olvidos.

#### Opci√≥n B: Trigger Autom√°tico

```sql
CREATE TRIGGER trg_refresh_analytics_on_update
ON dbo.scheduling_blocks
AFTER UPDATE, INSERT, DELETE
AS
BEGIN
    -- Find affected schedules
    DECLARE @schedule_ids TABLE (schedule_id BIGINT);
    
    INSERT INTO @schedule_ids
    SELECT DISTINCT ssb.schedule_id
    FROM inserted i
    JOIN dbo.schedule_scheduling_blocks ssb ON i.scheduling_block_id = ssb.scheduling_block_id
    UNION
    SELECT DISTINCT ssb.schedule_id
    FROM deleted d
    JOIN dbo.schedule_scheduling_blocks ssb ON d.scheduling_block_id = ssb.scheduling_block_id;
    
    -- Refresh analytics for each schedule
    DECLARE @sid BIGINT;
    DECLARE cur CURSOR FOR SELECT schedule_id FROM @schedule_ids;
    OPEN cur;
    FETCH NEXT FROM cur INTO @sid;
    WHILE @@FETCH_STATUS = 0
    BEGIN
        EXEC analytics.sp_populate_schedule_analytics @sid;
        FETCH NEXT FROM cur INTO @sid;
    END;
    CLOSE cur;
    DEALLOCATE cur;
END;
```

**Ventajas**: Autom√°tico, siempre consistente.

**Desventajas**: Overhead en writes. Cada UPDATE en `dbo.*` dispara un refresh completo de analytics.

#### Opci√≥n C: Eventual Consistency con Background Job

Un job (Azure Function, cron) que cada N minutos chequea schedules modificados y refresca analytics.

```sql
-- Table to track modifications
CREATE TABLE dbo.schedule_modification_log (
    schedule_id BIGINT PRIMARY KEY,
    last_modified_at DATETIME2 NOT NULL,
    analytics_refreshed_at DATETIME2 NULL
);

-- Background job logic
SELECT schedule_id 
FROM dbo.schedule_modification_log
WHERE last_modified_at > analytics_refreshed_at
   OR analytics_refreshed_at IS NULL;

-- For each schedule_id:
EXEC analytics.sp_populate_schedule_analytics @schedule_id;
UPDATE dbo.schedule_modification_log SET analytics_refreshed_at = GETUTCDATE() WHERE schedule_id = @schedule_id;
```

**Ventajas**: No overhead en writes. Escalable.

**Desventajas**: Eventual consistency (puede haber lag de minutos).

### 8.2 Extensi√≥n: Versionado de Schedules

**Feature Request**: Permitir m√∫ltiples versiones de un schedule para comparar cambios.

**Dise√±o**:
```sql
ALTER TABLE dbo.schedules ADD version INT NOT NULL DEFAULT 1;
ALTER TABLE dbo.schedules DROP CONSTRAINT UQ_schedules_checksum;
ALTER TABLE dbo.schedules ADD CONSTRAINT UQ_schedules_name_version UNIQUE (schedule_name, version);
```

Cada upload con el mismo `schedule_name` incrementa `version`. Analytics se mantiene separado por `schedule_id` (que incluye la versi√≥n impl√≠citamente).

### 8.3 Extensi√≥n: Incremental ETL

**Optimizaci√≥n**: En lugar de `DELETE + INSERT` completo, hacer **upsert** incremental.

```sql
-- Merge statement (SQL Server 2016+)
MERGE analytics.schedule_blocks_analytics AS target
USING (
    SELECT ... -- Full SELECT from sp_populate_schedule_analytics
) AS source
ON target.schedule_id = source.schedule_id 
   AND target.scheduling_block_id = source.scheduling_block_id
WHEN MATCHED THEN 
    UPDATE SET 
        target.priority = source.priority,
        target.total_visibility_hours = source.total_visibility_hours,
        ...
WHEN NOT MATCHED BY TARGET THEN
    INSERT (...) VALUES (...)
WHEN NOT MATCHED BY SOURCE AND target.schedule_id = @schedule_id THEN
    DELETE;
```

**Beneficio**: Si solo cambiaron 100 bloques de 5000, solo actualizamos 100 filas en lugar de DELETE + INSERT de 5000.

---

## Cap√≠tulo 9: Conclusi√≥n ‚Äî El C√≠rculo Completo del Dato

### 9.1 Recapitulaci√≥n del Viaje

Hemos seguido el viaje completo de los datos en TSI:

1. **Upload** ‚Üí Un operador sube `schedule.json`. Checksum SHA-256 garantiza unicidad.

2. **Normalizaci√≥n** ‚Üí El backend Rust descompone el JSON en **7 tablas relacionales 3NF**:
   - `schedules` ‚Üí Metadata del schedule.
   - `targets` ‚Üí Coordenadas celestes (deduplicadas).
   - `altitude_constraints`, `azimuth_constraints` ‚Üí Restricciones observacionales (deduplicadas).
   - `constraints` ‚Üí Combinaciones de restricciones (deduplicadas).
   - `scheduling_blocks` ‚Üí Core del schedule.
   - `schedule_scheduling_blocks` ‚Üí M:N con informaci√≥n de scheduling.
   - `schedule_dark_periods` ‚Üí Periodos no observables.

3. **ETL Transformation** ‚Üí Stored procedure `sp_populate_schedule_analytics` ejecuta:
   - Limpieza idempotente.
   - C√°lculo de priority buckets.
   - Gran JOIN con flattening de entidades.
   - Parsing de visibility JSON con `OPENJSON()`.
   - C√°lculo de m√©tricas precomputadas (`total_visibility_hours`, `visibility_period_count`).
   - Inserci√≥n en `analytics.schedule_blocks_analytics` (wide table).

4. **Validaci√≥n** ‚Üí Reglas Python/Rust marcan bloques imposibles y registran issues en `analytics.schedule_validation_results`.

5. **Consulta** ‚Üí La GUI Streamlit consulta analytics con **zero JOINs**, latencia <50ms, experiencia interactiva fluida.

### 9.2 Por Qu√© Esta Arquitectura Funciona

**Integridad en el Origen**:
- `dbo.*` mantiene normalizaci√≥n 3NF.
- Foreign keys, unique constraints, check constraints garantizan consistencia.
- ACID transactions aseguran que no quedamos en estado corrupto.

**Velocidad en las Consultas**:
- `analytics.*` sacrifica normalizaci√≥n por rendimiento.
- Wide table con datos precomputados.
- √çndices especializados para cada patr√≥n de consulta.
- Zero JOINs, zero parsing JSON en runtime.

**Control ETL Claro**:
- El proceso ETL es **expl√≠cito** (stored procedure).
- Es **idempotente** (puedes ejecutarlo N veces, mismo resultado).
- Es **auditable** (logs de cu√°ndo se refresc√≥, cu√°ntas filas).
- Es **extensible** (puedes a√±adir columnas computed, √≠ndices, etc.).

### 9.3 Tradeoffs y Filosof√≠a de Dise√±o

| Aspecto | Opci√≥n Elegida | Alternativa | Por Qu√© |
|---------|----------------|-------------|---------|
| **Almacenamiento temporal** | MJD (FLOAT) | DATETIME | Est√°ndar astron√≥mico, aritm√©tica simple |
| **Visibility periods** | JSON en `scheduling_blocks` | Tabla normalizada | Cardinalidad alta, acceso siempre completo |
| **Analytics schema** | Wide table denormalizada | Vistas materializadas | Control expl√≠cito, indexaci√≥n flexible |
| **Foreign keys en analytics** | No | S√≠ | Performance > integridad (eventual consistency OK) |
| **Refresh strategy** | Manual/on-demand | Triggers autom√°ticos | Evita overhead en writes, batch processing |
| **Backend language** | Rust + PyO3 | Pure Python | 10-100x speedup en computaci√≥n |

### 9.4 La Visi√≥n Final

Cada schedule vive su **ciclo de vida completo**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  JSON File  ‚îÇ  ‚Üê Operador sube schedule
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Checksum   ‚îÇ  ‚Üê SHA-256, unicidad garantizada
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Normalize   ‚îÇ  ‚Üê 7 tablas 3NF, integridad ACID
‚îÇ   (dbo.*)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ETL Proc   ‚îÇ  ‚Üê sp_populate_schedule_analytics
‚îÇ (analytics) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                  ‚îÇ
       ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Validation  ‚îÇ    ‚îÇ   Queries   ‚îÇ
‚îÇ   Results   ‚îÇ    ‚îÇ  (GUI/API)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  User Insights  ‚îÇ  ‚Üê Sky map, distributions, timeline, issues
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Cada etapa tiene su prop√≥sito. Cada decisi√≥n de dise√±o tiene su justificaci√≥n. El resultado es un sistema que **equilibra integridad, rendimiento y flexibilidad**.

---

## Ep√≠logo: Lecciones Aprendidas y Pr√≥ximos Pasos

### Lecciones Aprendidas

1. **Normalizaci√≥n no es enemiga de la velocidad** ‚Äî Si la usas en el lugar correcto (origen) y desnormalizas donde importa (analytics).

2. **ETL expl√≠cito > l√≥gica embebida** ‚Äî Un stored procedure claro es mejor que triggers complejos o l√≥gica distribuida en aplicaci√≥n.

3. **Precomputaci√≥n gana** ‚Äî Pagar el costo una vez (en ETL) para beneficio infinito (en queries) es buen tradeoff.

4. **√çndices son documentaci√≥n** ‚Äî Cada √≠ndice cuenta una historia sobre c√≥mo se usa el sistema.

5. **JSON tiene su lugar** ‚Äî Para datos semi-estructurados de alta cardinalidad, JSON columnar es pragm√°tico.

### Pr√≥ximos Pasos

**Optimizaciones Futuras**:
- **Columnstore indexes** en analytics para workloads con >10M bloques.
- **Partitioning** por `schedule_id` para retenci√≥n hist√≥rica eficiente.
- **Incremental ETL** para schedules modificados.
- **Materialized views** para agregaciones comunes (resumen por schedule).

**Features Potenciales**:
- **Change Data Capture (CDC)** para streaming de cambios.
- **Time-travel queries** para an√°lisis hist√≥rico.
- **A/B testing framework** para comparar estrategias de scheduling.

**Escalabilidad**:
- **Read replicas** para separar cargas anal√≠ticas de operacionales.
- **Caching layer** (Redis) para schedules activos.
- **Event-driven architecture** para refresh autom√°tico de analytics.

---

## Ap√©ndice: Glosario de T√©rminos

- **MJD (Modified Julian Date)**: Sistema de tiempo astron√≥mico. MJD = JD - 2400000.5. M√°s compacto que JD.
- **3NF (Third Normal Form)**: Nivel de normalizaci√≥n donde no hay dependencias transitivas entre atributos no-clave.
- **Wide Table**: Tabla con muchas columnas, t√≠picamente desnormalizada, optimizada para an√°lisis.
- **OPENJSON**: Funci√≥n SQL Server para parsear JSON y convertirlo en filas.
- **Computed Column**: Columna cuyo valor se deriva de otras columnas mediante f√≥rmula.
- **PERSISTED**: Modificador que hace que SQL Server almacene f√≠sicamente el valor computado.
- **Idempotente**: Operaci√≥n que puede ejecutarse m√∫ltiples veces con el mismo resultado.
- **OUTER APPLY**: Similar a LEFT JOIN pero para subqueries o funciones de tabla.
- **Priority Bucket**: Agrupaci√≥n de prioridades en cuartiles (Low, Med-Low, Med-High, High).
- **Checksum**: Hash criptogr√°fico que identifica √∫nicamente un conjunto de datos.

---

**Documento generado para**: TSI Engineering Team  
**Versi√≥n**: 1.0  
**Fecha**: Diciembre 2025  
**Autor**: TSI Platform Team

---

*Este documento describe el estado actual del sistema TSI. Para cambios o extensiones, consultar con el equipo de arquitectura de datos.*
